{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Assignment-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is Elastic Net Regression and how does it differ from other regression techniques?\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# Elastic Net Regression is a regression technique that combines the properties of Ridge Regression and Lasso \n",
    "# Regression. It is particularly useful when dealing with datasets that have a large number of features and \n",
    "# where those features might be correlated with each other. \n",
    "\n",
    "# Ordinary Least Squares (OLS) Regression:\n",
    "\n",
    "# OLS: Aims to minimize the sum of squared errors between predicted and actual values. It can overfit with many \n",
    "# features and struggles with multicollinearity.   \n",
    "# Elastic Net: Addresses these issues by adding penalty terms to the objective function, preventing overfitting \n",
    "# and handling multicollinearity.   \n",
    "\n",
    "# 2. Ridge Regression:\n",
    "\n",
    "# Ridge: Uses L2 regularization, adding a penalty proportional to the square of the magnitude of coefficients. \n",
    "# It shrinks coefficients towards zero but rarely eliminates them. Useful for multicollinearity.   \n",
    "# Elastic Net: Combines L1 and L2 regularization. It handles multicollinearity like Ridge but also performs feature \n",
    "# selection by shrinking some coefficients to exactly zero.   \n",
    "\n",
    "# 3. Lasso Regression:\n",
    "\n",
    "# Lasso: Uses L1 regularization, adding a penalty proportional to the absolute value of the magnitude of \n",
    "# coefficients. It can shrink some coefficients to zero, performing feature selection.   \n",
    "# Elastic Net: Offers a balance between Ridge and Lasso. It performs feature selection like Lasso but also \n",
    "# handles multicollinearity more effectively.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. How do you choose the optimal values of the regularization parameters for Elastic Net Regression?\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# By performing Cross-Validation techniques like GridSearchCV and RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. What are the advantages and disadvantages of Elastic Net Regression?\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# Elastic Net Regression, while a powerful tool, comes with its own set of advantages and disadvantages.\n",
    "\n",
    "# Advantages:\n",
    "\n",
    "# Handles Multicollinearity: Like Ridge Regression, Elastic Net effectively addresses multicollinearity, a common \n",
    "# issue where predictor variables are highly correlated. This leads to more stable and reliable coefficient estimates.\n",
    "# Performs Feature Selection: Similar to Lasso Regression, Elastic Net can shrink the coefficients of less \n",
    "# important features to zero, effectively performing feature selection. This results in a simpler and more \n",
    "# interpretable model.\n",
    "# Balances Feature Selection and Coefficient Shrinkage: Elastic Net combines the strengths of both Ridge and \n",
    "# Lasso by using both L1 and L2 regularization. This allows it to balance between feature selection and coefficient \n",
    "# shrinkage, offering a more versatile approach.\n",
    "\n",
    "# Disadvantages:\n",
    "\n",
    "# Hyperparameter Tuning: Elastic Net has two main hyperparameters to tune: alpha (overall regularization strength) \n",
    "# and l1_ratio (balance between L1 and L2 regularization). Finding the optimal values for these parameters can be \n",
    "# computationally expensive and requires careful consideration.\n",
    "# Complexity: Compared to simpler models like linear regression, Elastic Net is more complex. This can make \n",
    "# it slightly more challenging to understand and interpret the model, especially when dealing with a \n",
    "# large number of features.\n",
    "# Computational Cost: The process of fitting an Elastic Net model, especially with cross-validation for \n",
    "# hyperparameter tuning, can be computationally intensive, particularly for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. What are some common use cases for Elastic Net Regression?\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# 1. Finance:\n",
    "\n",
    "# Predicting loan defaults: Elastic Net can analyze various financial indicators (credit score, income, \n",
    "# spending patterns) to predict loan defaults, helping lenders assess risk.   \n",
    "# Credit risk assessment: Similar to loan defaults, it can be used to evaluate the creditworthiness of \n",
    "# individuals or businesses.   \n",
    "# Stock price forecasting: With numerous correlated factors influencing stock prices (market trends, \n",
    "# company performance), Elastic Net can identify key predictors and improve forecasting accuracy.\n",
    "\n",
    "\n",
    "# 2. Healthcare and Biostatistics:\n",
    "\n",
    "# Genomics: In genetic studies, Elastic Net can analyze vast amounts of gene expression data to identify \n",
    "# genes associated with diseases, aiding in diagnosis and treatment.   \n",
    "# Disease prediction: By analyzing patient data (age, medical history, lifestyle), it can predict disease \n",
    "# progression and inform personalized treatment plans.\n",
    "# Drug discovery: Elastic Net can help identify potential drug targets by analyzing complex biological datasets.   \n",
    "\n",
    "\n",
    "# 3. Marketing and Customer Analytics:\n",
    "\n",
    "# Customer segmentation: It can identify key factors influencing customer behavior (purchase history, \n",
    "# demographics) to segment customers effectively.   \n",
    "# Marketing campaign optimization: By analyzing data from various marketing channels, it can determine \n",
    "# the most effective strategies and allocate resources efficiently.   \n",
    "# Churn prediction: It can predict which customers are likely to leave, allowing businesses to take proactive\n",
    "# measures to retain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. How do you interpret the coefficients in Elastic Net Regression?\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# Interpreting coefficients in Elastic Net Regression requires a bit of nuance, as it combines aspects of \n",
    "# both Ridge and Lasso regression. \n",
    "\n",
    "# 1. Magnitude of Coefficients:\n",
    "\n",
    "# Larger magnitude: A larger absolute value of a coefficient indicates that the corresponding feature has a \n",
    "# stronger influence on the target variable.\n",
    "# Smaller magnitude: Conversely, a smaller magnitude suggests a weaker influence.\n",
    "# Zero coefficient: If a coefficient is exactly zero, it means that the feature was effectively removed \n",
    "# from the model by the Elastic Net's feature selection process. This indicates that the feature is not \n",
    "# considered important for predicting the target variable.\n",
    "\n",
    "# 2. Sign of Coefficients:\n",
    "\n",
    "# Positive sign: A positive coefficient means that an increase in the feature's value is associated with an \n",
    "# increase in the target variable (and vice versa).   \n",
    "# Negative sign: A negative coefficient indicates that an increase in the feature's value is associated with a \n",
    "# decrease in the target variable (and vice versa).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. How do you handle missing values when using Elastic Net Regression?\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# If the missing values are less then we can remove simply remove it.\n",
    "# Else:\n",
    "# Missing Completely at Random (MCAR): Imputation - Simple methods like mean/median imputation might be sufficient.\n",
    "# Missing at Random (MAR): Imputation - More advanced imputation techniques are needed, such as K-Nearest Neighbors \n",
    "# (KNN) imputation or Multiple Imputation (MI). MI is often preferred as it accounts for the uncertainty in the\n",
    "# imputation process.\n",
    "# Missing Not at Random (MNAR): Specialized techniques - This often requires more complex methods, sometimes \n",
    "# involving modeling the missing data mechanism itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. How do you use Elastic Net Regression for feature selection?\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# Elastic Net Regression is a combination of Ridge and Lasso Regression, and shrink coefficients of less \n",
    "# import features to zero. And the model remove those feature who have zero coefficient. Like this it helps\n",
    "# in feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.05644007]\n"
     ]
    }
   ],
   "source": [
    "# Q8. How do you pickle and unpickle a trained Elastic Net Regression model in Python?\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# Pickling and unpickling are essential for saving and loading trained machine learning models in Python.\n",
    "\n",
    "import pickle\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Train your model (example)\n",
    "# Sample Data (replace with your actual data loading)\n",
    "data = pd.DataFrame({'feature1': [1, 2, 3, 4, 5], 'feature2': [6, 7, 8, 9, 10], 'target': [11, 13, 15, 17, 19]})\n",
    "X = data[['feature1', 'feature2']]\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)  # Example parameters\n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "# 2. Pickle the model (save to disk)\n",
    "filename = 'elastic_net_model.pkl' # You can change the name\n",
    "with open(filename, 'wb') as file:  # 'wb' for write binary\n",
    "    pickle.dump(elastic_net, file)\n",
    "\n",
    "# 3. Unpickle the model (load from disk)\n",
    "loaded_elastic_net = None # Initialize\n",
    "with open(filename, 'rb') as file:  # 'rb' for read binary\n",
    "    loaded_elastic_net = pickle.load(file)\n",
    "\n",
    "# 4. Use the loaded model (example)\n",
    "# ... (your code to load new data) ...\n",
    "# predictions = loaded_elastic_net.predict(new_data)\n",
    "print(loaded_elastic_net.predict(X_test)) # Example: making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9. What is the purpose of pickling a model in machine learning?\n",
    "\n",
    "# Ans:\n",
    "\n",
    "# The purpose of pickling a model in machine learning is to save the trained model to disk so that it \n",
    "# can be loaded and used later without having to retrain it.  This is incredibly useful for several reasons:\n",
    "# Saving Training Time\n",
    "# Deployment\n",
    "# Reproducibility\n",
    "# Offline Analysis\n",
    "# Sharing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
